import { useRef, useEffect, useCallback, useState } from "react";
import {
  DrawingUtils,
  NormalizedLandmark,
  PoseLandmarker,
} from "@mediapipe/tasks-vision";
import { usePoseStore } from "@/store/poseStore";

interface UseWebcamCanvasProps {
  videoRef: React.RefObject<HTMLVideoElement | null>;
  isActive: boolean;
}

const drawSkeleton = (
  ctx: CanvasRenderingContext2D,
  landmarks: NormalizedLandmark[]
) => {
  const drawingUtils = new DrawingUtils(ctx);

  drawingUtils.drawConnectors(landmarks, PoseLandmarker.POSE_CONNECTIONS, {
    color: "#00FF00",
    lineWidth: 3,
  });

  drawingUtils.drawLandmarks(landmarks, {
    color: "#FFFFFF",
    radius: 3,
    fillColor: "#FFFFFF",
  });
};

export function useWebcamCanvas({ videoRef, isActive }: UseWebcamCanvasProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationRef = useRef<number>(0);
  const lastDetectionTime = useRef<number>(0);

  const workerRef = useRef<Worker | null>(null);
  const [isWorkerInitialized, setIsWorkerInitialized] = useState(false);
  
  // ğŸƒâ€â¡ï¸ ì›Œì»¤ê°€ í˜„ì¬ í¬ì¦ˆ ì¶”ì • ì¤‘ì¸ì§€ ì—¬ë¶€ (busy flag)
  const workerBusyRef = useRef<boolean>(false);
  
  const lastDrawnLandmarks = useRef<NormalizedLandmark[] | null>(null);

  const { webcam, setWebcamData } = usePoseStore();

  useEffect(() => {
    const worker = new Worker(
      new URL("../workers/pose-worker.js", import.meta.url),
      { type: "module" }
    );
    workerRef.current = worker;

    worker.onmessage = (event) => {
      const { type, landmarks, angles, poseClass, fps, latency, vectorized } =
        event.data;

      if (type === "INITIALIZED") {
        setIsWorkerInitialized(true);
      } else if (type === "RESULT" && landmarks) {
        // ğŸƒâ€â¡ï¸ ì›Œì»¤ê°€ ì´ í”„ë ˆì„ ì²˜ë¦¬ë¥¼ ëëƒˆìœ¼ë‹ˆ busy í•´ì œ
        workerBusyRef.current = false;

        // ì›Œì»¤ì—ì„œ ë°›ì€ ê²°ê³¼ëŠ” ì €ì¥ë§Œ í•˜ê³ , ë“œë¡œì‰ì€ detectLoop ë‚´ì—ì„œ ì‹¤í–‰
        lastDrawnLandmarks.current = landmarks;

        // Storeì— ë¶„ì„ ê²°ê³¼ ì €ì¥
        setWebcamData(landmarks, angles, fps, vectorized, poseClass, latency);
      }
    };

    // ì›Œì»¤ì—ê²Œ ì´ˆê¸°í™” ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
    worker.postMessage({ type: "INIT" });

    return () => {
      worker.terminate();
      workerRef.current = null;
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // ê°ì§€ ë£¨í”„ ì‹œì‘/ì¤‘ì§€
  useEffect(() => {
    if (isActive && isWorkerInitialized && videoRef.current) {
      const loopWrapper = (timestamp: number) => {
        detectLoop(timestamp);
      };
      animationRef.current = requestAnimationFrame(loopWrapper);
    } else if (!isActive && animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive, isWorkerInitialized]);

  // ë©”ì¸ ìŠ¤ë ˆë“œ detectLoop (ë Œë”ë§ ë° ì „ì†¡ ë‹´ë‹¹)
  const detectLoop = useCallback(
    async (now: number) => {
      const videoElement = videoRef.current;
      const canvas = canvasRef.current;
      const ctx = canvas?.getContext("2d");
      const worker = workerRef.current;

      if (
        !videoElement ||
        !canvas ||
        !ctx ||
        !worker ||
        !isActive ||
        !videoElement.videoWidth
      ) {
        animationRef.current = requestAnimationFrame(detectLoop);
        return;
      }

      // ğŸƒâ€â¡ï¸ ì„±ëŠ¥ì„ ìœ„í•´ í•´ìƒë„ ì œí•œ
      videoElement.width = 640;
      videoElement.height = 360;

      const FRAME_INTERVAL = 33; // 30 FPS ëª©í‘œ (1000ms / 30 = 33.3ms)
      const shouldDetect = now - lastDetectionTime.current >= FRAME_INTERVAL;

      canvas.width = videoElement.videoWidth;
      canvas.height = videoElement.videoHeight;

      // 1. ë¹„ë””ì˜¤ í”„ë ˆì„ ë Œë”ë§ (60 FPS ìœ ì§€)
      ctx.save();

      ctx.translate(-canvas.width, 0);
      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
      ctx.restore();

      // 2. ì´ì „ í”„ë ˆì„ì˜ ê²°ê³¼ ìŠ¤ì¼ˆë ˆí†¤ ë“œë¡œì‰ (ëŠê¹€ ë°©ì§€)
      if (lastDrawnLandmarks.current) {
        drawSkeleton(ctx, lastDrawnLandmarks.current);
      }

      // ğŸƒâ€â¡ï¸ ì›Œì»¤ê°€ í•œê°€í•  ë•Œë§Œ í”„ë ˆì„ ì „ì†¡
      if (shouldDetect && !workerBusyRef.current) {
        try {
          // ğŸƒâ€â¡ï¸ ì›Œì»¤ ì ìœ  ì‹œì‘
          workerBusyRef.current = true;
          
          // 3. ImageBitmap ìƒì„±
          const imageBitmap = await createImageBitmap(videoElement);

          // 4. ì›Œì»¤ë¡œ ì „ì†¡
          worker.postMessage(
            {
              type: "DETECT",
              imageBitmap,
              timestamp: now,
              previousAngles: webcam.previousAngles,
              lastFrameTime: lastDetectionTime.current,
            },
            [imageBitmap]
          );

          lastDetectionTime.current = now;
        } catch (e) {
          console.error("Webcam Worker communication failed:", e);
        }
      }

      if (isActive) {
        animationRef.current = requestAnimationFrame(detectLoop);
      }
    },
    [isActive, videoRef, webcam.previousAngles]
  );

  return { canvasRef };
}
