import { useRef, useEffect, useCallback } from "react";
import {
  DrawingUtils,
  Landmark,
  NormalizedLandmark,
  PoseLandmarker,
} from "@mediapipe/tasks-vision";
import {
  calculateAllAngles,
  vectorize,
} from "@/lib/mediapipe/angle-calculator";
import { usePoseStore } from "@/store/poseStore";
import { JointAngles } from "@/types/pose";
import { classifyPoseWithVectorized } from "@/lib/poseClassifier/pose-classifier-with-vectorized";

interface UseWebcamCanvasProps {
  videoRef: React.RefObject<HTMLVideoElement | null>;
  isActive: boolean;
  isInitialized: boolean;
  detectForVideo: (video: HTMLVideoElement, timestamp: number) => Promise<any>;
}

// ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
const drawSkeleton = (
  ctx: CanvasRenderingContext2D,
  landmarks: NormalizedLandmark[]
) => {
  const drawingUtils = new DrawingUtils(ctx);

  drawingUtils.drawConnectors(landmarks, PoseLandmarker.POSE_CONNECTIONS, {
    color: "#00FF00",
    lineWidth: 3,
  });

  drawingUtils.drawLandmarks(landmarks, {
    color: "#FFFFFF",
    radius: 3,
    fillColor: "#FFFFFF",
  });
};

const sequenceData: Landmark[][] = [];
const startTime = Date.now();

export function useWebcamCanvas({
  videoRef,
  isActive,
  isInitialized,
  detectForVideo,
}: UseWebcamCanvasProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationRef = useRef<number>(0);
  const lastFrameTime = useRef<number>(0);

  const { webcam, setWebcamData, setPreviousAngles } = usePoseStore();

  // í¬ì¦ˆ ê°ì§€ ë£¨í”„
  const detectLoop = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current || !isActive) {
      animationRef.current = requestAnimationFrame(detectLoop);
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");

    if (video.readyState === video.HAVE_ENOUGH_DATA && ctx) {
      // ìº”ë²„ìŠ¤ í¬ê¸° ì¡°ì •
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      // ë¹„ë””ì˜¤ í”„ë ˆìž„ ê·¸ë¦¬ê¸°
      ctx.save();
      ctx.scale(-1, 1);
      ctx.translate(-canvas.width, 0);
      ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
      ctx.restore();

      // í¬ì¦ˆ ê°ì§€
      const detectStartTime = performance.now();

      // ì›¹ì›Œì»¤ë¥¼ í†µí•œ í¬ì¦ˆ ê°ì§€
      const results = await detectForVideo(video, detectStartTime);

      if (results && results.landmarks && results.landmarks.length > 0) {
        const landmarks = results.landmarks[0];
        const worldLandmarks = results.worldLandmarks?.[0];

        // ðŸ‘‰ ì „ì²˜ë¦¬ ì „, í›„ jitter ê°’ ë¹„êµë¥¼ ìœ„í•œ ì½”ë“œ
        // (ì½˜ì†”ì°½ì— ì°ì–´ í™•ì¸í•˜ë¯€ë¡œ ì‹¤ì œ ì„œë¹„ìŠ¤ì‹œì—ëŠ” ì£¼ì„ ì²˜ë¦¬ í•„ìš”)
        const elapsed = (Date.now() - startTime) / 1000;
        if (elapsed >= 10) {
          // getJitter3D(sequenceData);
        } else {
          sequenceData.push(landmarks);
        }

        // ë²¡í„°í™”
        const data = vectorize(landmarks, video.videoHeight, video.videoWidth);

        // 2D ëžœë“œë§ˆí¬ê°€ ê°ì§€ë˜ì—ˆë‹¤ë©´, ê°ë„ ê³„ì‚° ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ìŠ¤ì¼ˆë ˆí†¤ì„ ì¦‰ì‹œ ê·¸ë¦¼
        drawSkeleton(ctx, landmarks);

        if (worldLandmarks) {
          // ê°ë„ ê³„ì‚°
          const angles = calculateAllAngles(
            worldLandmarks,
            webcam.previousAngles,
            (angles: JointAngles) => setPreviousAngles("webcam", angles)
          );

          // FPS ê³„ì‚°
          const fps = lastFrameTime.current
            ? Math.round(1000 / (detectStartTime - lastFrameTime.current))
            : 0;
          lastFrameTime.current = detectStartTime;

          // í¬ì¦ˆ ë¶„ë¥˜
          const poseClass = classifyPoseWithVectorized(data);

          // ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (ms)
          const latency = Math.round(performance.now() - detectStartTime);

          // Storeì— ì €ìž¥
          setWebcamData(
            landmarks,
            angles,
            fps,
            data,
            poseClass.bestPose,
            latency
          );

          // ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
          drawSkeleton(ctx, landmarks);
        }
      }
    }

    if (isActive) {
      animationRef.current = requestAnimationFrame(detectLoop);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive, detectForVideo, setWebcamData, videoRef]);

  useEffect(() => {
    if (isActive && isInitialized && videoRef.current) {
      detectLoop();
    } else if (!isActive && animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive, isInitialized]);

  return { canvasRef };
}
