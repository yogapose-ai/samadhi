import { useRef, useEffect, useCallback } from "react";
import { JointAngles } from "@/types";
import {
  DrawingUtils,
  Landmark,
  NormalizedLandmark,
  PoseLandmarker,
} from "@mediapipe/tasks-vision";
import {
  calculateAllAngles,
  vectorize,
} from "@/lib/mediapipe/angle-calculator";
import { classifyPoseWithVectorized } from "@/lib/poseClassifier/pose-classifier-with-vectorized";
import { usePoseStore } from "@/store/poseStore";

interface UseWebcamCanvasProps {
  videoRef: React.RefObject<HTMLVideoElement | null>;
  isActive: boolean;
  isInitialized: boolean;
  landmarker: PoseLandmarker | null;
}

// ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
const drawSkeleton = (
  ctx: CanvasRenderingContext2D,
  landmarks: NormalizedLandmark[]
) => {
  const drawingUtils = new DrawingUtils(ctx);

  drawingUtils.drawConnectors(landmarks, PoseLandmarker.POSE_CONNECTIONS, {
    color: "#00FF00",
    lineWidth: 3,
  });

  drawingUtils.drawLandmarks(landmarks, {
    color: "#FFFFFF",
    radius: 3,
    fillColor: "#FFFFFF",
  });
};

const sequenceData: Landmark[][] = [];
const startTime = Date.now();

export function useWebcamCanvas({
  videoRef,
  isActive,
  isInitialized,
  landmarker,
}: UseWebcamCanvasProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationRef = useRef<number>(0);
  const lastFrameTime = useRef<number>(0);

  const { webcam, setWebcamData, setPreviousAngles } = usePoseStore();

  // í¬ì¦ˆ ê°ì§€ ë£¨í”„
  const detectLoop = useCallback(() => {
    if (!videoRef.current || !canvasRef.current || !landmarker || !isActive) {
      animationRef.current = requestAnimationFrame(detectLoop);
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");

    if (video.readyState === video.HAVE_ENOUGH_DATA && ctx) {
      // ìº”ë²„ìŠ¤ í¬ê¸° ì¡°ì •
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      // ë¹„ë””ì˜¤ í”„ë ˆìž„ ê·¸ë¦¬ê¸°
      ctx.save();
      ctx.scale(-1, 1);
      ctx.translate(-canvas.width, 0);
      ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
      ctx.restore();

      // console.log('ë¹„ë””ì˜¤ ì¢Œí‘œ', videoLandmarks);
      // console.log('ë²¡í„°', vec);

      // í¬ì¦ˆ ê°ì§€
      const detectStartTime = performance.now();
      const results = landmarker.detectForVideo(video, detectStartTime);
      // const detectEndTime = performance.now();
      // const detectionLatency = detectEndTime - detectStartTime;

      if (results.landmarks && results.landmarks.length > 0) {
        const landmarks = results.landmarks[0];
        const worldLandmarks = results.worldLandmarks?.[0];

        // ðŸ‘‰ ì „ì²˜ë¦¬ ì „, í›„ jitter ê°’ ë¹„êµë¥¼ ìœ„í•œ ì½”ë“œ
        // (ì½˜ì†”ì°½ì— ì°ì–´ í™•ì¸í•˜ë¯€ë¡œ ì‹¤ì œ ì„œë¹„ìŠ¤ì‹œì—ëŠ” ì£¼ì„ ì²˜ë¦¬ í•„ìš”)
        const elapsed = (Date.now() - startTime) / 1000;
        if (elapsed >= 10) {
          // getJitter3D(sequenceData);
        } else {
          sequenceData.push(landmarks);
        }

        const data = vectorize(landmarks, video.videoHeight, video.videoWidth);

        // 2D ëžœë“œë§ˆí¬ê°€ ê°ì§€ë˜ì—ˆë‹¤ë©´, ê°ë„ ê³„ì‚° ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ìŠ¤ì¼ˆë ˆí†¤ì„ ì¦‰ì‹œ ê·¸ë¦¼
        drawSkeleton(ctx, landmarks);

        if (worldLandmarks) {
          // const totalLatency = performance.now() - detectStartTime;

          // ê°ë„ ê³„ì‚°
          const angles = calculateAllAngles(
            worldLandmarks,
            webcam.previousAngles,
            (angles: JointAngles) => setPreviousAngles("webcam", angles)
          );

          // FPS ê³„ì‚°
          const fps = lastFrameTime.current
            ? Math.round(1000 / (detectStartTime - lastFrameTime.current))
            : 0;
          lastFrameTime.current = detectStartTime;

          // í¬ì¦ˆ ë¶„ë¥˜
          const poseClass = classifyPoseWithVectorized(data);

          // ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (ms)
          const latency = Math.round(performance.now() - detectStartTime);

          // Storeì— ì €ìž¥
          setWebcamData(
            landmarks,
            angles,
            fps,
            data,
            poseClass.bestPose,
            latency
          );

          // ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
          drawSkeleton(ctx, landmarks);
        } else {
          // í¬ì¦ˆ ê°ì§€ ì•ˆ ë˜ë©´ ì•Œë¦¼
          // ctx.fillStyle = "#FF0000";
          // ctx.font = "bold 20px Arial";
          // ctx.fillText(
          //   "í¬ì¦ˆê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ì‹ ì„ ë³´ì—¬ì£¼ì„¸ìš”!",
          //   20,
          //   40
          // );
        }
      } else {
        // ëžœë“œë§ˆí¬ ì—†ìœ¼ë©´ ì•Œë¦¼
        // ctx.fillStyle = "#FFFF00";
        // ctx.font = "bold 20px Arial";
        // ctx.fillText("ì‚¬ëžŒì„ ì°¾ëŠ” ì¤‘...", 20, 40);
      }
    }

    if (isActive) {
      animationRef.current = requestAnimationFrame(detectLoop);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive, landmarker, setWebcamData, videoRef]);

  useEffect(() => {
    if (isActive && isInitialized && videoRef.current) {
      detectLoop();
    } else if (!isActive && animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive, isInitialized]);

  return { canvasRef };
}
